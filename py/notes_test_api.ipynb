{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependency\n",
    "import os \n",
    "import json\n",
    "import petpy\n",
    "import urllib\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import giphy_client\n",
    "from giphy_client.rest import ApiException\n",
    "from pprint import pprint\n",
    "\n",
    "#database \n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#\n",
    "from config import key, secret, api_key \n",
    "import config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Petfinder API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cats():\n",
    "    # initialized\n",
    "    pf = petpy.Petfinder(key=key, secret=secret)\n",
    "    \n",
    "    #params\n",
    "    after_date = '2021-01-01'\n",
    "    before_date = '2021-04-18'\n",
    "    animal_type = 'cat'\n",
    "    status = 'adoptable'\n",
    "    location = 'Miami, FL'\n",
    "    distance = '10'\n",
    "    results_per_page =5\n",
    "    pages = 2\n",
    "    \n",
    "    \n",
    "    #api call\n",
    "    api_res = pf.animals(animal_type=animal_type, status=status, location=location, distance=distance,\n",
    "                     after_date=after_date, before_date=before_date,\n",
    "                     results_per_page=results_per_page, pages=pages, return_df=True)\n",
    "    \n",
    "    # filtered the data few columns \n",
    "    new_cat_df = api_res[['id','species','age','gender','animal_id','contact.address.city','published_at']]\n",
    "    new_cat_df\n",
    "    \n",
    "    #reset index to id\n",
    "    new_cat_df = new_cat_df.set_index('id')\n",
    "\n",
    "    #rename columns\n",
    "    new_cat_df = new_cat_df.rename(columns={'contact.address.city':'city', 'published_at':'date_published'})\n",
    "   \n",
    "    #--------Database Connection----------\n",
    "    # Create a SQL Database connection\n",
    "    connection_string = f\"postgres:{config.password}@localhost:5432/pets_db\"\n",
    "    engine = create_engine(f'postgresql://{connection_string}')\n",
    "    \n",
    "    # checking tables\n",
    "    engine.table_names()\n",
    "    \n",
    "    try:\n",
    "        new_cat_df.to_sql(name=\"stage_cat_db\", con=engine, if_exists=\"append\", index=True)\n",
    "        print(\"Data loaded successfully\")\n",
    "    \n",
    "    except:\n",
    "         print(\"Data has already been loaded to db\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return \n",
    "get_cats()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data collection and storing into the database\n",
    "def get_dogs():\n",
    "    \n",
    "    # initialized\n",
    "    pf = petpy.Petfinder(key=key, secret=secret)\n",
    "    \n",
    "    #params\n",
    "    after_date = '2021-01-01'\n",
    "    before_date = '2021-04-18'\n",
    "    animal_type = 'dog'\n",
    "    status = 'adoptable'\n",
    "    location = 'Miami, FL'\n",
    "    distance = '50'\n",
    "    results_per_page = 1\n",
    "    pages = 20\n",
    "    \n",
    "    \n",
    "    #api call\n",
    "    api_res = pf.animals(animal_type=animal_type, status=status, location=location, distance=distance,\n",
    "                     after_date=after_date, before_date=before_date,\n",
    "                     results_per_page=results_per_page, pages=pages, return_df=True)\n",
    "    \n",
    "    # filtered the data few columns \n",
    "    new_dog_df = api_res[['id','species','age','gender','animal_id','contact.address.city','published_at']]\n",
    "    #reset index to id\n",
    "    new_dog_df = new_dog_df.set_index('id')\n",
    "    \n",
    "    #rename columns\n",
    "    new_dog_df = new_dog_df.rename(columns={'contact.address.city':'city', 'published_at':'date_published'})\n",
    "    \n",
    "    \n",
    "  #--------Database Connection----------\n",
    "    # Create a SQL Database connection\n",
    "    connection_string = f\"postgres:{config.password}@localhost:5432/pets_db\"\n",
    "    engine = create_engine(f'postgresql://{connection_string}')\n",
    "    \n",
    "    # checking tables\n",
    "    engine.table_names()\n",
    "    \n",
    "    try:\n",
    "        new_dog_df.to_sql(name=\"stage_dog_db\", con=engine, if_exists=\"append\", index=True)\n",
    "        print(\"Data loaded successfully\")\n",
    "    \n",
    "    except:\n",
    "        print(\"Data has already been loaded to db\")\n",
    "\n",
    "    \n",
    "    return \n",
    "get_dogs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giphy API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependency\n",
    "import giphy_client\n",
    "from giphy_client.rest import ApiException\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_giphy():\n",
    "    #params\n",
    "    api_instance = giphy_client.DefaultApi()\n",
    "    api_key = config.api_key \n",
    "    limit = 100\n",
    "    #increase offset by 100 each run \n",
    "    offset = 200 \n",
    "    \n",
    "    \n",
    "    #empty list\n",
    "    gif_url = []\n",
    "    slug = []\n",
    "    gif_id = []\n",
    "    trending_datetime= []\n",
    "\n",
    "    try: \n",
    "        # trending endpoint\n",
    "        api_response = api_instance.gifs_trending_get(api_key, limit=limit)\n",
    "        #pprint(api_response.data)\n",
    "\n",
    "        api_res = api_response.data\n",
    "\n",
    "        # iterate over the api response \n",
    "        for item in api_res:\n",
    "#             print(item)\n",
    "\n",
    "            gif_id.append(item.id)\n",
    "            slug.append(item.slug)\n",
    "            trending_datetime.append(item.trending_datetime)\n",
    "            gif_url.append(item.bitly_gif_url)\n",
    "            \n",
    "\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling DefaultApi->gifs_search_get: %s\\n\" % e)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #create df for the list items (slug and gif_url)\n",
    "    giphy_df = pd.DataFrame({'slug':slug,\n",
    "                            'gif_url':gif_url,'gif_id':gif_id,\n",
    "                            'trending_datetime':trending_datetime})\n",
    "    \n",
    "    #removing duplicate times with value of '0000-00-00 00:00:00'\n",
    "    giphy_df.drop_duplicates(subset =\"trending_datetime\",\n",
    "                     keep = False, inplace = True)\n",
    "    \n",
    "    #reset index to gif_url\n",
    "    giphy_df = giphy_df.set_index('gif_id')\n",
    "\n",
    "    \n",
    "    #--------Database Connection----------\n",
    "    # Create a SQL Database connection\n",
    "    connection_string = f\"postgres:{config.password}@localhost:5432/pets_db\"\n",
    "    engine = create_engine(f'postgresql://{connection_string}')\n",
    "        \n",
    "    # checking tables\n",
    "    engine.table_names()\n",
    "    \n",
    "    try:\n",
    "        giphy_df.to_sql(name=\"stage_giphy_db\", con=engine, if_exists=\"append\", index=True)\n",
    "        #print(\"Data loaded successfully\")\n",
    "    \n",
    "    except:\n",
    "        print(\"Data has already been loaded to db\")\n",
    "        \n",
    "    return #trending_datetime\n",
    "get_giphy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data validation stet\n",
    "def update_db():\n",
    "    \n",
    "    # Create a SQL Database connection\n",
    "    connection_string = f\"postgres:{config.password}@localhost:5432/pets_db\"\n",
    "    engine = create_engine(f'postgresql://{connection_string}')\n",
    "    \n",
    "    #check for connection\n",
    "#     engine.table_names()\n",
    "    \n",
    "    # handle the any duplicates from staging db to final dog_db, cat_db \n",
    "    engine.execute(\n",
    "        \"\"\"INSERT INTO dog_db \n",
    "        SELECT DISTINCT * FROM stage_dog_db\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            species = EXCLUDED.species,\n",
    "            age = EXCLUDED.age,\n",
    "            gender = EXCLUDED.gender,\n",
    "            animal_id = EXCLUDED.animal_id,\n",
    "            city = EXCLUDED.city,\n",
    "            date_published = EXCLUDED.date_published\"\"\")\n",
    "    \n",
    "    engine.execute(\n",
    "        \"\"\"INSERT INTO cat_db \n",
    "        SELECT DISTINCT * FROM stage_cat_db\n",
    "        ON CONFLICT (id) DO UPDATE SET\n",
    "            species = EXCLUDED.species,\n",
    "            age = EXCLUDED.age,\n",
    "            gender = EXCLUDED.gender,\n",
    "            animal_id = EXCLUDED.animal_id,\n",
    "            city = EXCLUDED.city,\n",
    "            date_published = EXCLUDED.date_published\"\"\")\n",
    "    \n",
    "    engine.execute(\n",
    "        \"\"\"INSERT INTO giphy_db \n",
    "        SELECT DISTINCT(*) \n",
    "        FROM stage_giphy_db\n",
    "        WHERE slug LIKE '%cat%' OR slug LIKE '%dog'\n",
    "            ON CONFLICT (gif_id) DO UPDATE SET\n",
    "            slug = EXCLUDED.slug,\n",
    "            gif_url = EXCLUDED.gif_url,\n",
    "            trending_datetime = EXCLUDED.trending_datetime\n",
    "        \"\"\")\n",
    "    \n",
    "    return\n",
    "update_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt lib \n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.ext.automap import automap_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cat Adoption Date Trending  Dog Adoption Date Trending\n",
      "0              1    2021-03-09             2    2021-04-04\n",
      "1              3    2021-04-15             1    2021-02-06\n",
      "2              1    2021-04-13             1    2021-04-09\n",
      "3              1    2021-02-14             1    2021-03-14\n",
      "4              4    2021-04-06             1    2021-04-05\n",
      "5              4    2021-04-14             1    2021-02-14\n",
      "6              5    2021-04-12             1    2021-01-16\n",
      "7              1    2021-04-17             1    2021-03-27\n",
      "8              2    2021-04-10             1    2021-02-12\n",
      "9              2    2021-03-25             3    2021-02-09\n",
      "10             3    2021-02-07             2    2021-01-08\n",
      "11             1    2021-04-16             1    2021-02-26\n",
      "12             3    2021-03-07             3    2021-03-12\n"
     ]
    }
   ],
   "source": [
    "def make_Daliy_Chart():\n",
    "    \n",
    "    # Create a SQL Database connection\n",
    "    connection_string = f\"postgres:{config.password}@localhost:5432/pets_db\"\n",
    "    engine = create_engine(f'postgresql://{connection_string}')\n",
    "\n",
    "    #check for connection to db and show all table names \n",
    "    engine.table_names()\n",
    "    \n",
    "    # reflect an existing database \n",
    "    Base = automap_base()\n",
    "\n",
    "    # reflect the tables\n",
    "    Base.prepare(engine, reflect=True)\n",
    "\n",
    "    #view all of the tables with pkey \n",
    "    Base.classes.keys()\n",
    "    \n",
    "    # Save references to each table in the db\n",
    "    cat_db = Base.classes.cat_db\n",
    "    dog_db = Base.classes.dog_db\n",
    "    giphy_db = Base.classes.giphy_db\n",
    "    \n",
    "    # Create(link) btw Python and DB\n",
    "    session = Session(engine)\n",
    "    \n",
    "    #Inspector to explore the database and print the table names\n",
    "    inspector = inspect(engine)\n",
    "    inspector.get_table_names()\n",
    "    \n",
    "    # Use Inspector to print the column names and types\n",
    "    cat_table = inspector.get_columns('cat_db')\n",
    "\n",
    "    dog_table = inspector.get_columns('dog_db')\n",
    "\n",
    "    giphy_table = inspector.get_columns('giphy_db')\n",
    "\n",
    "    \n",
    "    #query the db for \n",
    "    #Giphy Daily Trending Dog post\n",
    "    #Giphy Daily Trending Cat post\n",
    "    #Pet adoption Cat and Dog Trending \n",
    "    \n",
    "    #---------Cat adoption stats-----------\n",
    "    cat_adoption = engine.execute(\"\"\"SELECT COUNT(species) as daily_vol, \n",
    "    cast(cast(date_published as date) as varchar) \n",
    "    FROM cat_db\n",
    "    WHERE date_published >= '2021-01-01' AND date_published < '2021/04/18'\n",
    "    Group by cast(date_published as date)\n",
    "    \"\"\").fetchall()\n",
    "\n",
    "\n",
    "    cat_adop_dates = [x[1] for x in cat_adoption]\n",
    "    cat_adop_count = [x[0] for x in cat_adoption]\n",
    "    \n",
    "    \n",
    "#     pprint(f' Dates for CAT Adop {cat_adop_dates}')\n",
    "#     pprint(f' Count CAT Adop {cat_adop_count}')\n",
    "\n",
    "\n",
    " #---------Dog adoption stats-----------\n",
    "\n",
    "    dog_adoption = engine.execute(\"\"\"SELECT COUNT(species) as daily_vol, \n",
    "    cast(cast(date_published as date) as varchar) \n",
    "    FROM dog_db\n",
    "    WHERE date_published >= '2021-01-01' AND date_published < '2021/04/18'\n",
    "    Group by cast(date_published as date)\n",
    "    \"\"\").fetchall()\n",
    "    #list comprehension\n",
    "    dog_adop_dates = [x[1] for x in dog_adoption]\n",
    "    dog_adop_count = [x[0] for x in dog_adoption]\n",
    "\n",
    "#     pprint(f' Dates for DOG Adop {dog_adop_dates}')\n",
    "#     pprint(f' Count DOG Adop {dog_adop_count}')\n",
    "\n",
    "\n",
    " #---------giphy trends stats-----------\n",
    "    \n",
    "#     pet_trends = engine.execute(\"\"\"\n",
    "#     SELECT COUNT(*) as daily_vol, \n",
    "#     cast(cast(trending_datetime as date) as varchar) \n",
    "#     FROM giphy_db \n",
    "#     Group by cast(trending_datetime as date)\n",
    "#     \"\"\").fetchall()\n",
    "\n",
    "#     #list comprehension\n",
    "#     giphy_adop_dates = [x[1] for x in pet_trends]\n",
    "#     giphy_adop_count = [x[0] for x in pet_trends]\n",
    "\n",
    "#     print(giphy_adop_dates)\n",
    "#     print(giphy_adop_count)\n",
    "    \n",
    "    ###----------------Make Graphs----------\n",
    "    \n",
    "    cat_adoption = pd.DataFrame({'Cat Adoption': cat_adop_count,\n",
    "                             'Date Trending': cat_adop_dates})\n",
    "    \n",
    "#     print(len(cat_adoption))\n",
    "    \n",
    "    dog_adoption = pd.DataFrame({'Dog Adoption': dog_adop_count,\n",
    "                         'Date Trending': dog_adop_dates})\n",
    "    \n",
    "#     print(len(dog_adoption))\n",
    "    \n",
    "    #new df for cats and dogs to make the graph\n",
    "    \n",
    "    combine_adoption = pd.concat([cat_adoption, dog_adoption], axis=1, join='inner')\n",
    "    print(combine_adoption)\n",
    "    \n",
    "#     pet_post = pd.DataFrame({'Pet Post': giphy_adop_count,\n",
    "#                              'Date Trending': giphy_adop_dates})\n",
    "    \n",
    "    \n",
    "#     fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "#     #bar graph is for the pet trends posts\n",
    "#     pet_post['Pet Post'].plot(kind='bar', color='y')\n",
    "    \n",
    "#     #line graph is for Cats and Dog adoptions numbers\n",
    "#     cat_adoption['Cat Adoption'].plot(kind='line', marker='d', secondary_y=True)\n",
    "#     cat_adoption['Date Trending'].plot(kind='line', marker='d', secondary_y=True)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "make_Daliy_Chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stage_cat_db',\n",
       " 'stage_dog_db',\n",
       " 'cat_db',\n",
       " 'dog_db',\n",
       " 'stage_giphy_db',\n",
       " 'giphy_db']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a SQL Database connection\n",
    "connection_string = f\"postgres:{config.password}@localhost:5432/pets_db\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')\n",
    "\n",
    "#check for connection and table names\n",
    "engine.table_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat_db', 'dog_db', 'giphy_db']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflect an existing database \n",
    "Base = automap_base()\n",
    "\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "#view all of the classes \n",
    "Base.classes.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "cat_db = Base.classes.cat_db\n",
    "dog_db = Base.classes.dog_db\n",
    "giphy_db = Base.classes.giphy_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stage_cat_db',\n",
       " 'stage_dog_db',\n",
       " 'cat_db',\n",
       " 'dog_db',\n",
       " 'stage_giphy_db',\n",
       " 'giphy_db']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspector to explore the database and print the table names\n",
    "inspector = inspect(engine)\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id INTEGER\n",
      "species VARCHAR(4)\n",
      "age VARCHAR(10)\n",
      "gender VARCHAR(6)\n",
      "animal_id INTEGER\n",
      "city VARCHAR\n",
      "date_published TIMESTAMP WITHOUT TIME ZONE\n"
     ]
    }
   ],
   "source": [
    "# Use Inspector to print the column names and types\n",
    "cat_table = inspector.get_columns('cat_db')\n",
    "for c in cat_table:\n",
    "    print(c['name'], c[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id INTEGER\n",
      "species VARCHAR(4)\n",
      "age VARCHAR(10)\n",
      "gender VARCHAR(6)\n",
      "animal_id INTEGER\n",
      "city VARCHAR\n",
      "date_published TIMESTAMP WITHOUT TIME ZONE\n"
     ]
    }
   ],
   "source": [
    "dog_table = inspector.get_columns('dog_db')\n",
    "for c in dog_table:\n",
    "    print(c['name'], c[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gif_id VARCHAR(255)\n",
      "slug VARCHAR(255)\n",
      "gif_url VARCHAR(255)\n",
      "trending_datetime TIMESTAMP WITHOUT TIME ZONE\n"
     ]
    }
   ],
   "source": [
    "giphy_table = inspector.get_columns('giphy_db')\n",
    "for c in giphy_table:\n",
    "    print(c['name'], c[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "    # query the db for \n",
    "    #Giphy Daily Trending Dog post\n",
    "    #Giphy Daily Trending Cat post\n",
    "    #Pet addopption Cat and Dog Trending \n",
    "cat_adoption = engine.execute(\"\"\"SELECT COUNT(species) as daily_vol, \n",
    "cast(cast(date_published as date) as varchar) \n",
    "FROM cat_db\n",
    "WHERE date_published >= '2021-01-01' AND date_published < '2021/04/18'\n",
    "Group by cast(date_published as date)\n",
    "\"\"\").fetchall()\n",
    "\n",
    "c_adop_dates = [x[1] for x in cat_adoption]\n",
    "c_adop_count = [x[0] for x in cat_adoption]\n",
    "\n",
    "# print(cat_adoption)\n",
    "print(len(c_adop_dates))\n",
    "print(len(c_adop_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "dog_adoption = engine.execute(\"\"\"SELECT COUNT(species) as daily_vol, \n",
    "cast(cast(date_published as date) as varchar) \n",
    "FROM dog_db\n",
    "WHERE date_published >= '2021-01-01' AND date_published < '2021/01/07'\n",
    "Group by cast(date_published as date)\n",
    "\n",
    "\"\"\").fetchall()\n",
    "#list comprehension\n",
    "d_adop_dates = [x[1] for x in dog_adoption]\n",
    "d_adop_count = [x[0] for x in dog_adoption]\n",
    "\n",
    "print(len(d_adop_dates))\n",
    "print(len(d_adop_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_trends = engine.execute(\"\"\"\n",
    "SELECT COUNT(*) as daily_vol, \n",
    "cast(cast(trending_datetime as date) as varchar) \n",
    "FROM giphy_db \n",
    "Group by cast(trending_datetime as date)\n",
    "\"\"\").fetchall()\n",
    "\n",
    "#list comprehension\n",
    "giphy_adop_dates = [x[1] for x in pet_trends]\n",
    "giphy_adop_count = [x[0] for x in pet_trends]\n",
    "\n",
    "print(giphy_adop_dates)\n",
    "print(giphy_adop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need dog post data\n",
    "dog_trends_date = engine.execute(\"\"\"SELECT COUNT(species) as daily_vol, \n",
    "cast(cast(date_published as date) as varchar) \n",
    "FROM cat_db \n",
    "Group by cast(date_published as date)\n",
    "\"\"\").fetchall()\n",
    "dog_trends_date\n",
    "# for item in dog_trends_date:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need dog post data\n",
    "cat_trends_date = engine.execute('SELECT COUNT(species) as daily_vol, cast(date_published as date) FROM cat_db Group by cast(date_published as date)').fetchall()\n",
    "cat_trends_date\n",
    "# for item in cat_trends_date:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a': [100, 200, 150, 175],\n",
    "                   'b': [430, 30, 20, 10]})\n",
    "fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "df['b'].plot(kind='bar', color='y')\n",
    "df['a'].plot(kind='line', marker='d', secondary_y=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
